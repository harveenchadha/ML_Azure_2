{"4120a8f3-c9a7-462a-8908-224627bb4a0d_8":{"AUC_micro":[0.9676457408912663],"AUC_macro":[0.8998378244206229],"f1_score_macro":[0.5199117885295454],"f1_score_weighted":[0.8481491160835534],"precision_score_macro":[0.8595593706814075],"recall_score_micro":[0.8925644916540213],"recall_score_macro":[0.5250617304532581],"precision_score_micro":[0.8925644916540213],"f1_score_micro":[0.8925644916540213],"average_precision_score_macro":[0.7538501216870752],"weighted_accuracy":[0.9838054864786838],"AUC_weighted":[0.8998378244206229],"norm_macro_recall":[0.050123460906516204],"precision_score_weighted":[0.8855347767531138],"recall_score_weighted":[0.8925644916540213],"matthews_correlation":[0.18985447089769078],"average_precision_score_micro":[0.968330423918571],"accuracy":[0.8925644916540213],"log_loss":[0.25101544537718573],"average_precision_score_weighted":[0.9336295533341482],"balanced_accuracy":[0.5250617304532581]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_23":{"accuracy":[0.8995447647951441],"average_precision_score_macro":[0.7373638143290058],"weighted_accuracy":[0.9768435955650944],"AUC_micro":[0.9648652370239545],"average_precision_score_micro":[0.9657337884631718],"AUC_macro":[0.8839754597135856],"f1_score_macro":[0.6200834695056934],"precision_score_weighted":[0.8819023417184951],"f1_score_micro":[0.8995447647951441],"recall_score_micro":[0.8995447647951441],"recall_score_weighted":[0.8995447647951441],"precision_score_macro":[0.7980516431924882],"matthews_correlation":[0.32426987445816596],"precision_score_micro":[0.8995447647951441],"norm_macro_recall":[0.17639720142929383],"recall_score_macro":[0.5881986007146469],"f1_score_weighted":[0.8729435303886112],"log_loss":[0.25492551980585826],"AUC_weighted":[0.8839754597135856],"average_precision_score_weighted":[0.9281922155003437],"balanced_accuracy":[0.5881986007146469]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_14":{"AUC_macro":[0.8640313829659145],"average_precision_score_micro":[0.9582841528017128],"norm_macro_recall":[0.0],"matthews_correlation":[0.0],"f1_score_micro":[0.8880121396054628],"precision_score_weighted":[0.788565560086672],"recall_score_macro":[0.5],"f1_score_weighted":[0.8353395018439429],"weighted_accuracy":[0.9843450583187134],"average_precision_score_weighted":[0.9117198150426721],"AUC_weighted":[0.8640313829659145],"precision_score_micro":[0.8880121396054628],"precision_score_macro":[0.4440060698027314],"average_precision_score_macro":[0.6810710930153795],"recall_score_weighted":[0.8880121396054628],"recall_score_micro":[0.8880121396054628],"AUC_micro":[0.9604154913523733],"balanced_accuracy":[0.5],"accuracy":[0.8880121396054628],"f1_score_macro":[0.4703423886834914],"log_loss":[0.26527722206839716]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_20":{"f1_score_macro":[0.5845512548138593],"precision_score_macro":[0.5971984211851311],"AUC_micro":[0.8178347199163675],"recall_score_micro":[0.7047040971168437],"average_precision_score_micro":[0.7940252963402141],"balanced_accuracy":[0.7224236681874678],"precision_score_weighted":[0.8757110993587777],"norm_macro_recall":[0.4448473363749357],"f1_score_weighted":[0.7579320774824435],"average_precision_score_macro":[0.7129549736922453],"recall_score_weighted":[0.7047040971168437],"log_loss":[0.5396466462185661],"matthews_correlation":[0.29406957939934797],"precision_score_micro":[0.7047040971168437],"accuracy":[0.7047040971168437],"weighted_accuracy":[0.7003048069262952],"AUC_macro":[0.8471974466839678],"f1_score_micro":[0.7047040971168437],"recall_score_macro":[0.7224236681874678],"AUC_weighted":[0.8471974466839679],"average_precision_score_weighted":[0.917267254140595]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_18":{"average_precision_score_macro":[0.7576011664122269],"f1_score_weighted":[0.8511179174565592],"matthews_correlation":[0.48474163845555285],"recall_score_micro":[0.824886191198786],"precision_score_micro":[0.824886191198786],"AUC_micro":[0.8691694087468712],"recall_score_macro":[0.833905717731135],"average_precision_score_micro":[0.8349899728386835],"weighted_accuracy":[0.8226468867348683],"log_loss":[0.46838743358519874],"norm_macro_recall":[0.66781143546227],"precision_score_weighted":[0.9094567582004255],"f1_score_macro":[0.7062485350783174],"accuracy":[0.824886191198786],"precision_score_macro":[0.6759287454323994],"recall_score_weighted":[0.824886191198786],"AUC_weighted":[0.9029678779357856],"balanced_accuracy":[0.833905717731135],"AUC_macro":[0.9029678779357855],"f1_score_micro":[0.824886191198786],"average_precision_score_weighted":[0.934983810998125]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_38":{"AUC_micro":[0.9794612244146071],"f1_score_micro":[0.9125948406676783],"balanced_accuracy":[0.6985659825839543],"precision_score_macro":[0.802903852022651],"precision_score_micro":[0.9125948406676783],"norm_macro_recall":[0.3971319651679086],"weighted_accuracy":[0.9657324167472157],"f1_score_macro":[0.7359599332220367],"average_precision_score_micro":[0.9804086552424867],"log_loss":[0.20308453106429047],"f1_score_weighted":[0.9035500847391074],"accuracy":[0.9125948406676783],"recall_score_micro":[0.9125948406676783],"AUC_macro":[0.9442981066857832],"recall_score_weighted":[0.9125948406676783],"average_precision_score_weighted":[0.9540492167889637],"precision_score_weighted":[0.9019083906620209],"matthews_correlation":[0.4904952640152294],"recall_score_macro":[0.6985659825839543],"AUC_weighted":[0.9442981066857832],"average_precision_score_macro":[0.819579846190879]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_0":{"recall_score_micro":[0.9116843702579667],"norm_macro_recall":[0.5026785366965085],"f1_score_weighted":[0.9091539479147899],"precision_score_weighted":[0.9072720074188747],"balanced_accuracy":[0.7513392683482543],"average_precision_score_macro":[0.8151093723721079],"average_precision_score_micro":[0.9806603102489483],"AUC_macro":[0.9450464668693166],"weighted_accuracy":[0.9514937218005303],"precision_score_micro":[0.9116843702579667],"recall_score_weighted":[0.9116843702579667],"AUC_micro":[0.979695082216353],"f1_score_macro":[0.7653697272147331],"matthews_correlation":[0.5323740218566827],"AUC_weighted":[0.9450464668693167],"f1_score_micro":[0.9116843702579667],"average_precision_score_weighted":[0.9531771295804466],"recall_score_macro":[0.7513392683482543],"precision_score_macro":[0.7819118765348991],"accuracy":[0.9116843702579667],"log_loss":[0.17775706110025447]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_24":{"average_precision_score_micro":[0.9460205940517346],"f1_score_macro":[0.5666954309243181],"precision_score_micro":[0.8849772382397572],"precision_score_weighted":[0.8486862398357069],"norm_macro_recall":[0.10552249063160479],"log_loss":[0.2996175782424307],"recall_score_micro":[0.8849772382397572],"AUC_weighted":[0.8328368963799002],"f1_score_micro":[0.8849772382397572],"recall_score_macro":[0.5527612453158024],"AUC_micro":[0.9499862070871163],"accuracy":[0.8849772382397572],"average_precision_score_weighted":[0.9057223522145289],"recall_score_weighted":[0.8849772382397572],"f1_score_weighted":[0.8548847302534887],"weighted_accuracy":[0.9674574829922197],"matthews_correlation":[0.19213028725485287],"average_precision_score_macro":[0.6643463635860718],"balanced_accuracy":[0.5527612453158024],"AUC_macro":[0.8328368963799002],"precision_score_macro":[0.6749108036575107]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_25":{"f1_score_weighted":[0.8438595430915632],"average_precision_score_weighted":[0.9378466626204924],"recall_score_micro":[0.8895295902883156],"average_precision_score_macro":[0.7595753049706668],"AUC_weighted":[0.9182277571237777],"matthews_correlation":[0.13205757507671706],"log_loss":[0.23627523619886628],"recall_score_macro":[0.517432253953435],"precision_score_macro":[0.7500996598277878],"accuracy":[0.8895295902883156],"precision_score_weighted":[0.8598326029449221],"weighted_accuracy":[0.9819112938376251],"average_precision_score_micro":[0.972672915984033],"f1_score_macro":[0.5063499746461992],"AUC_macro":[0.9182277571237776],"norm_macro_recall":[0.0348645079068699],"f1_score_micro":[0.8895295902883156],"recall_score_weighted":[0.8895295902883156],"balanced_accuracy":[0.517432253953435],"precision_score_micro":[0.8895295902883156],"AUC_micro":[0.9712212139144931]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_11":{"AUC_macro":[0.924443407113497],"log_loss":[0.8139899740966237],"AUC_micro":[0.9198428667153296],"precision_score_macro":[0.7002386846015918],"f1_score_micro":[0.8540212443095598],"average_precision_score_weighted":[0.9382682947257384],"AUC_weighted":[0.9244434071134972],"average_precision_score_micro":[0.9081012976532392],"f1_score_weighted":[0.8732589092297715],"recall_score_macro":[0.8479421021141176],"average_precision_score_macro":[0.7590027636681898],"accuracy":[0.85402124430956],"matthews_correlation":[0.5279070707798622],"balanced_accuracy":[0.8479421021141176],"recall_score_micro":[0.85402124430956],"precision_score_micro":[0.85402124430956],"f1_score_macro":[0.7377473136347834],"precision_score_weighted":[0.9149967431342376],"norm_macro_recall":[0.6958842042282352],"recall_score_weighted":[0.85402124430956],"weighted_accuracy":[0.8555305308786744]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_12":{"f1_score_macro":[0.6406874321558489],"average_precision_score_macro":[0.7675207934247861],"AUC_micro":[0.9720032881935889],"recall_score_weighted":[0.9001517450682853],"average_precision_score_weighted":[0.9391263879752317],"precision_score_micro":[0.9001517450682853],"log_loss":[0.23352825342562228],"AUC_macro":[0.9168472733941284],"balanced_accuracy":[0.6051182094185945],"precision_score_weighted":[0.8816394555510353],"AUC_weighted":[0.9168472733941283],"accuracy":[0.9001517450682853],"recall_score_micro":[0.9001517450682853],"matthews_correlation":[0.34570996806564047],"weighted_accuracy":[0.9734005914479992],"precision_score_macro":[0.7842404343666571],"norm_macro_recall":[0.21023641883718902],"recall_score_macro":[0.6051182094185945],"f1_score_weighted":[0.8776339493405274],"f1_score_micro":[0.9001517450682853],"average_precision_score_micro":[0.9727208624964262]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_3":{"matthews_correlation":[0.5134080478239689],"precision_score_weighted":[0.9169293726128859],"average_precision_score_micro":[0.8554179593744945],"weighted_accuracy":[0.8210556499426224],"average_precision_score_macro":[0.7590027919777302],"AUC_macro":[0.9214101402804868],"log_loss":[0.43596968064717445],"recall_score_weighted":[0.8282245827010623],"recall_score_macro":[0.85709978938477],"f1_score_macro":[0.7164088911272418],"balanced_accuracy":[0.85709978938477],"norm_macro_recall":[0.7141995787695401],"f1_score_micro":[0.8282245827010623],"AUC_micro":[0.887272802632397],"f1_score_weighted":[0.8545977376010256],"AUC_weighted":[0.9214101402804867],"accuracy":[0.8282245827010623],"precision_score_macro":[0.6845337293705364],"average_precision_score_weighted":[0.9380764703658528],"recall_score_micro":[0.8282245827010623],"precision_score_micro":[0.8282245827010623]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_9":{"precision_score_micro":[0.8974203338391502],"AUC_micro":[0.9647161169841646],"f1_score_macro":[0.6669471737564983],"log_loss":[0.24945212755737153],"AUC_weighted":[0.9074793413689435],"precision_score_weighted":[0.8788643450255851],"accuracy":[0.8974203338391502],"AUC_macro":[0.9074793413689435],"precision_score_macro":[0.7499304771008951],"weighted_accuracy":[0.9630231751451572],"norm_macro_recall":[0.26636713735558404],"average_precision_score_weighted":[0.9366993238957716],"recall_score_weighted":[0.8974203338391502],"balanced_accuracy":[0.633183568677792],"recall_score_micro":[0.8974203338391502],"f1_score_micro":[0.8974203338391502],"recall_score_macro":[0.633183568677792],"matthews_correlation":[0.3648924929983646],"average_precision_score_macro":[0.7635753150165687],"average_precision_score_micro":[0.9613619971660987],"f1_score_weighted":[0.8819489506012049]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_6":{"precision_score_macro":[0.8019920345482998],"log_loss":[0.23905313317256557],"norm_macro_recall":[0.16658238352718446],"f1_score_micro":[0.8992412746585736],"f1_score_weighted":[0.8714135569458731],"f1_score_macro":[0.6136038678466876],"AUC_weighted":[0.9024089232690002],"AUC_macro":[0.9024089232690002],"weighted_accuracy":[0.9776831339362634],"recall_score_micro":[0.8992412746585736],"precision_score_weighted":[0.881974764352729],"accuracy":[0.8992412746585736],"AUC_micro":[0.968408196536344],"average_precision_score_micro":[0.9692905550239607],"matthews_correlation":[0.3171956901386891],"recall_score_weighted":[0.8992412746585736],"balanced_accuracy":[0.5832911917635922],"average_precision_score_macro":[0.740717350494552],"average_precision_score_weighted":[0.931517780892862],"recall_score_macro":[0.5832911917635922],"precision_score_micro":[0.8992412746585736]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_17":{"norm_macro_recall":[0.38849155408847325],"log_loss":[0.23741795182409225],"average_precision_score_weighted":[0.9337866890703315],"f1_score_macro":[0.7133005313251694],"precision_score_micro":[0.8965098634294385],"weighted_accuracy":[0.9467265649279225],"matthews_correlation":[0.43108492284498995],"precision_score_macro":[0.7391740679411912],"precision_score_weighted":[0.8875723080973876],"AUC_weighted":[0.9069838306038562],"AUC_macro":[0.9069838306038562],"recall_score_macro":[0.6942457770442366],"balanced_accuracy":[0.6942457770442366],"recall_score_weighted":[0.8965098634294385],"accuracy":[0.8965098634294385],"average_precision_score_macro":[0.7484992756381232],"AUC_micro":[0.966957338681637],"average_precision_score_micro":[0.9660080714906718],"f1_score_weighted":[0.8911540856875904],"recall_score_micro":[0.8965098634294385],"f1_score_micro":[0.8965098634294385]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_29":{"precision_score_macro":[0.7656484400966574],"precision_score_weighted":[0.8877585836712569],"f1_score_micro":[0.9022761760242792],"balanced_accuracy":[0.6643368398824111],"average_precision_score_weighted":[0.9362056070511353],"f1_score_macro":[0.6984405163338208],"AUC_macro":[0.9144725264750938],"recall_score_weighted":[0.9022761760242792],"AUC_micro":[0.9711802266274601],"recall_score_micro":[0.9022761760242792],"average_precision_score_micro":[0.9724147760199604],"recall_score_macro":[0.6643368398824111],"average_precision_score_macro":[0.7549468352721767],"f1_score_weighted":[0.8908391068943605],"norm_macro_recall":[0.3286736797648222],"precision_score_micro":[0.9022761760242792],"matthews_correlation":[0.41787952888447016],"AUC_weighted":[0.9144725264750938],"weighted_accuracy":[0.9613500770381658],"log_loss":[0.21986583681314295],"accuracy":[0.9022761760242792]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_37":{"weighted_accuracy":[0.9560308161860515],"f1_score_micro":[0.9125948406676783],"precision_score_macro":[0.78816180483959],"average_precision_score_weighted":[0.9539277691519797],"matthews_correlation":[0.5233715441011244],"AUC_macro":[0.9454243517144674],"AUC_micro":[0.9799208346669551],"recall_score_macro":[0.737642331994065],"balanced_accuracy":[0.737642331994065],"log_loss":[0.17929507406881962],"recall_score_weighted":[0.9125948406676783],"precision_score_weighted":[0.9059608691166807],"average_precision_score_macro":[0.8183891438401152],"accuracy":[0.9125948406676783],"AUC_weighted":[0.9454243517144674],"f1_score_macro":[0.7594758837162618],"norm_macro_recall":[0.4752846639881301],"precision_score_micro":[0.9125948406676783],"f1_score_weighted":[0.9084013964301347],"recall_score_micro":[0.9125948406676783],"average_precision_score_micro":[0.9808593843544582]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_22":{"norm_macro_recall":[0.46549763173639924],"f1_score_weighted":[0.7814850789778318],"recall_score_micro":[0.735660091047041],"weighted_accuracy":[0.7363828819252861],"accuracy":[0.735660091047041],"f1_score_macro":[0.6068584111104216],"average_precision_score_macro":[0.7125587476521201],"average_precision_score_micro":[0.8020593014384765],"recall_score_weighted":[0.735660091047041],"average_precision_score_weighted":[0.912267022776392],"AUC_macro":[0.8245387118942961],"matthews_correlation":[0.3158478151354512],"AUC_weighted":[0.824538711894296],"balanced_accuracy":[0.7327488158681996],"precision_score_micro":[0.735660091047041],"recall_score_macro":[0.7327488158681996],"f1_score_micro":[0.735660091047041],"AUC_micro":[0.8279602377262647],"log_loss":[0.5675796141447453],"precision_score_macro":[0.6071539740747058],"precision_score_weighted":[0.8775985346494063]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_1":{"f1_score_macro":[0.7416848907681176],"matthews_correlation":[0.488678780261868],"accuracy":[0.9071320182094081],"AUC_macro":[0.9392346349984347],"balanced_accuracy":[0.7191727470931578],"recall_score_weighted":[0.9071320182094081],"precision_score_macro":[0.7723958081530135],"precision_score_micro":[0.9071320182094081],"AUC_micro":[0.9781770788959222],"norm_macro_recall":[0.43834549418631563],"average_precision_score_micro":[0.9791945367231853],"recall_score_macro":[0.7191727470931578],"f1_score_weighted":[0.9021127651963996],"average_precision_score_macro":[0.8065229883244922],"average_precision_score_weighted":[0.9505970434373063],"recall_score_micro":[0.9071320182094081],"f1_score_micro":[0.9071320182094081],"precision_score_weighted":[0.8991976076061607],"log_loss":[0.1874363495858499],"AUC_weighted":[0.9392346349984347],"weighted_accuracy":[0.9537972210153172]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_13":{"AUC_micro":[0.8342708983354097],"precision_score_micro":[0.7353566009104704],"norm_macro_recall":[0.476997186239805],"accuracy":[0.7353566009104704],"average_precision_score_weighted":[0.9201166194624335],"f1_score_micro":[0.7353566009104705],"AUC_weighted":[0.8531227366272296],"average_precision_score_macro":[0.7196713810011088],"precision_score_weighted":[0.8796137361716039],"log_loss":[0.5867718432375195],"recall_score_weighted":[0.7353566009104704],"weighted_accuracy":[0.7345765292343196],"AUC_macro":[0.8531227366272296],"recall_score_macro":[0.7384985931199025],"balanced_accuracy":[0.7384985931199025],"f1_score_weighted":[0.7814530874914682],"f1_score_macro":[0.6086250578908656],"matthews_correlation":[0.3227404326461478],"precision_score_macro":[0.609184487738526],"average_precision_score_micro":[0.824526079125931],"recall_score_micro":[0.7353566009104704]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_33":{"average_precision_score_micro":[0.9793488243667532],"balanced_accuracy":[0.724763683043529],"average_precision_score_macro":[0.809408807756427],"AUC_weighted":[0.9399237191278269],"average_precision_score_weighted":[0.9513421484543777],"recall_score_macro":[0.724763683043529],"f1_score_micro":[0.908649468892261],"precision_score_macro":[0.7767506466136603],"AUC_micro":[0.9783186462221465],"norm_macro_recall":[0.449527366087058],"precision_score_weighted":[0.9011568762582128],"recall_score_weighted":[0.908649468892261],"weighted_accuracy":[0.9543033354921573],"log_loss":[0.18598497314459558],"f1_score_weighted":[0.9039219348737966],"precision_score_micro":[0.908649468892261],"f1_score_macro":[0.7469309675333606],"accuracy":[0.908649468892261],"matthews_correlation":[0.49881256847663513],"recall_score_micro":[0.908649468892261],"AUC_macro":[0.9399237191278269]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_32":{"f1_score_micro":[0.9104704097116844],"precision_score_weighted":[0.9059829376322037],"recall_score_macro":[0.748287477748325],"average_precision_score_macro":[0.8131814658112817],"accuracy":[0.9104704097116844],"AUC_weighted":[0.9412383916239879],"log_loss":[0.1853302697837681],"AUC_macro":[0.9412382119378269],"average_precision_score_weighted":[0.9522893790359487],"f1_score_macro":[0.7621445688259322],"precision_score_micro":[0.9104704097116844],"matthews_correlation":[0.5259098746256278],"f1_score_weighted":[0.9079052049308007],"recall_score_weighted":[0.9104704097116844],"weighted_accuracy":[0.950736044744107],"AUC_micro":[0.9785974518802343],"recall_score_micro":[0.9104704097116844],"average_precision_score_micro":[0.9795900063185161],"norm_macro_recall":[0.4965749554966501],"balanced_accuracy":[0.748287477748325],"precision_score_macro":[0.7784888697740712]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_4":{"balanced_accuracy":[0.6479419168764483],"accuracy":[0.9047040971168437],"recall_score_weighted":[0.9047040971168437],"matthews_correlation":[0.41166727171713335],"recall_score_micro":[0.9047040971168437],"precision_score_macro":[0.7863791854619517],"f1_score_weighted":[0.8896821852348699],"log_loss":[0.3151431428111519],"average_precision_score_macro":[0.7618004928613651],"average_precision_score_weighted":[0.9366978751328887],"AUC_macro":[0.9148166054456168],"recall_score_macro":[0.6479419168764483],"average_precision_score_micro":[0.9692348464246958],"norm_macro_recall":[0.2958838337528966],"AUC_micro":[0.9700782672969803],"AUC_weighted":[0.9148166054456168],"precision_score_micro":[0.9047040971168437],"f1_score_micro":[0.9047040971168437],"precision_score_weighted":[0.8893947792997314],"f1_score_macro":[0.6875188763811471],"weighted_accuracy":[0.9684512011710767]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_2":{"AUC_micro":[0.9684028543730901],"recall_score_micro":[0.8934749620637329],"recall_score_weighted":[0.8934749620637329],"f1_score_micro":[0.8934749620637329],"average_precision_score_weighted":[0.9329421900301925],"average_precision_score_micro":[0.9691528895474891],"precision_score_macro":[0.7920099322451494],"average_precision_score_macro":[0.7486887280132718],"norm_macro_recall":[0.08430444181406949],"precision_score_micro":[0.8934749620637329],"log_loss":[0.23526299110801466],"matthews_correlation":[0.2218906683125344],"balanced_accuracy":[0.5421522209070347],"f1_score_weighted":[0.8552440034655189],"precision_score_weighted":[0.873112177086074],"accuracy":[0.8934749620637329],"AUC_macro":[0.9033087152470978],"AUC_weighted":[0.9033087152470978],"f1_score_macro":[0.5507064298342631],"recall_score_macro":[0.5421522209070347],"weighted_accuracy":[0.9806988955735909]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_5":{"precision_score_macro":[0.7798605414273996],"precision_score_weighted":[0.8789484651839053],"average_precision_score_weighted":[0.9251302468396442],"recall_score_weighted":[0.8986342943854325],"AUC_macro":[0.8845376560395817],"norm_macro_recall":[0.1895814925339958],"accuracy":[0.8986342943854325],"log_loss":[0.2527386564011291],"weighted_accuracy":[0.9740704285543305],"matthews_correlation":[0.3257495330623777],"recall_score_macro":[0.5947907462669979],"AUC_micro":[0.9648441446897286],"f1_score_macro":[0.6276085302899465],"average_precision_score_micro":[0.9658308628203539],"average_precision_score_macro":[0.7220089396311172],"AUC_weighted":[0.8845376560395816],"f1_score_micro":[0.8986342943854325],"balanced_accuracy":[0.5947907462669979],"precision_score_micro":[0.8986342943854325],"recall_score_micro":[0.8986342943854325],"f1_score_weighted":[0.874144595317395]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_19":{"balanced_accuracy":[0.5],"accuracy":[0.8880121396054628],"log_loss":[0.2849043701692152],"AUC_micro":[0.9605929801211657],"average_precision_score_weighted":[0.9201661306301068],"AUC_macro":[0.8649237654372443],"average_precision_score_macro":[0.7143407325702888],"matthews_correlation":[0.0],"f1_score_macro":[0.4703423886834914],"AUC_weighted":[0.8649237654372444],"precision_score_weighted":[0.788565560086672],"average_precision_score_micro":[0.9608382503372925],"f1_score_weighted":[0.8353395018439429],"recall_score_macro":[0.5],"recall_score_weighted":[0.8880121396054628],"weighted_accuracy":[0.9843450583187134],"precision_score_micro":[0.8880121396054628],"norm_macro_recall":[0.0],"precision_score_macro":[0.4440060698027314],"recall_score_micro":[0.8880121396054628],"f1_score_micro":[0.8880121396054628]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_28":{"average_precision_score_weighted":[0.9412558463871321],"f1_score_micro":[0.8971168437025797],"norm_macro_recall":[0.14761219382528745],"accuracy":[0.8971168437025797],"matthews_correlation":[0.2919701779881593],"recall_score_micro":[0.8971168437025797],"log_loss":[0.22169022593071808],"f1_score_weighted":[0.8674942493719553],"AUC_weighted":[0.9245980805672718],"precision_score_macro":[0.7887518389413495],"balanced_accuracy":[0.5738060969126437],"f1_score_macro":[0.5998441656143367],"AUC_micro":[0.973031009876094],"recall_score_weighted":[0.8971168437025797],"average_precision_score_micro":[0.9743825951159588],"average_precision_score_macro":[0.7716968052017819],"precision_score_weighted":[0.8774772046712457],"AUC_macro":[0.9245980805672718],"recall_score_macro":[0.5738060969126437],"precision_score_micro":[0.8971168437025797],"weighted_accuracy":[0.9773861567227974]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_30":{"average_precision_score_macro":[0.796831618373547],"average_precision_score_micro":[0.9778706505022495],"accuracy":[0.9034901365705614],"f1_score_macro":[0.7240699893821417],"log_loss":[0.1930968980039682],"recall_score_macro":[0.6981760572903064],"matthews_correlation":[0.4564791248253349],"AUC_macro":[0.9349033151985655],"AUC_weighted":[0.9349033151985655],"precision_score_macro":[0.7628637311822937],"f1_score_micro":[0.9034901365705614],"f1_score_weighted":[0.8967374023895898],"AUC_micro":[0.9767375501115637],"norm_macro_recall":[0.3963521145806128],"precision_score_weighted":[0.8932887288528779],"weighted_accuracy":[0.9544640688039752],"average_precision_score_weighted":[0.948011267928616],"recall_score_micro":[0.9034901365705614],"recall_score_weighted":[0.9034901365705614],"precision_score_micro":[0.9034901365705614],"balanced_accuracy":[0.6981760572903064]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_27":{"f1_score_macro":[0.7532324924087248],"recall_score_micro":[0.906525037936267],"average_precision_score_weighted":[0.9512796793646534],"accuracy":[0.906525037936267],"precision_score_weighted":[0.9022928077169412],"weighted_accuracy":[0.9475386245712485],"f1_score_micro":[0.9065250379362669],"AUC_micro":[0.9783323700553328],"matthews_correlation":[0.5077000526701819],"AUC_macro":[0.9411963019151723],"balanced_accuracy":[0.7413294877993208],"recall_score_macro":[0.7413294877993208],"AUC_weighted":[0.9411963019151723],"precision_score_micro":[0.906525037936267],"norm_macro_recall":[0.4826589755986417],"average_precision_score_micro":[0.9793590203488491],"f1_score_weighted":[0.904163966769112],"average_precision_score_macro":[0.8085577541137163],"log_loss":[0.18331567518136963],"precision_score_macro":[0.7670201493317375],"recall_score_weighted":[0.906525037936267]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_10":{"weighted_accuracy":[0.9843450583187134],"AUC_macro":[0.8959774713946729],"accuracy":[0.8880121396054628],"AUC_weighted":[0.895977471394673],"recall_score_micro":[0.8880121396054628],"average_precision_score_macro":[0.726080571175317],"average_precision_score_weighted":[0.927742083713735],"f1_score_macro":[0.4703423886834914],"recall_score_macro":[0.5],"f1_score_weighted":[0.8353395018439429],"f1_score_micro":[0.8880121396054628],"norm_macro_recall":[0.0],"precision_score_weighted":[0.788565560086672],"AUC_micro":[0.966769349798863],"log_loss":[0.264477450365334],"average_precision_score_micro":[0.9682431371438427],"recall_score_weighted":[0.8880121396054628],"balanced_accuracy":[0.5],"matthews_correlation":[0.0],"precision_score_macro":[0.4440060698027314],"precision_score_micro":[0.8880121396054628]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_16":{"recall_score_micro":[0.7132018209408194],"precision_score_macro":[0.6056683895814331],"f1_score_macro":[0.5957632039781644],"recall_score_weighted":[0.7132018209408194],"matthews_correlation":[0.31943853748490414],"average_precision_score_weighted":[0.9199312288767281],"norm_macro_recall":[0.48283587757271973],"recall_score_macro":[0.7414179387863599],"weighted_accuracy":[0.7061965221128452],"f1_score_micro":[0.7132018209408193],"average_precision_score_macro":[0.7110120966694172],"balanced_accuracy":[0.7414179387863599],"precision_score_micro":[0.7132018209408194],"AUC_micro":[0.8355468463966877],"precision_score_weighted":[0.8820130971050018],"AUC_macro":[0.8611759442953282],"log_loss":[0.5286705165820785],"AUC_weighted":[0.8611759442953282],"accuracy":[0.7132018209408194],"average_precision_score_micro":[0.8449993596298551],"f1_score_weighted":[0.7648457172515365]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_21":{"accuracy":[0.7223065250379362],"precision_score_macro":[0.6040828528561423],"recall_score_micro":[0.7223065250379362],"AUC_weighted":[0.8577615509579566],"AUC_macro":[0.8577615509579566],"recall_score_macro":[0.7323348096775568],"average_precision_score_macro":[0.7116462647253493],"average_precision_score_micro":[0.7956791771316716],"log_loss":[0.5322527662191865],"matthews_correlation":[0.31101170273177164],"recall_score_weighted":[0.7223065250379362],"precision_score_micro":[0.7223065250379362],"AUC_micro":[0.8221016346559025],"f1_score_macro":[0.5984450178972779],"precision_score_weighted":[0.8781516921751333],"norm_macro_recall":[0.46466961935511364],"average_precision_score_weighted":[0.9194048903519852],"balanced_accuracy":[0.7323348096775568],"weighted_accuracy":[0.7198167732224282],"f1_score_micro":[0.7223065250379364],"f1_score_weighted":[0.7715127084757825]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_26":{"precision_score_micro":[0.9004552352048558],"weighted_accuracy":[0.9531578519545022],"norm_macro_recall":[0.3763566343797409],"f1_score_micro":[0.9004552352048558],"recall_score_micro":[0.9004552352048558],"AUC_weighted":[0.7193450181255061],"average_precision_score_micro":[0.8786649222132157],"accuracy":[0.9004552352048558],"average_precision_score_weighted":[0.8686105875529067],"AUC_micro":[0.9131817417754864],"f1_score_weighted":[0.8931597750193134],"average_precision_score_macro":[0.6403056713531701],"recall_score_weighted":[0.9004552352048558],"matthews_correlation":[0.4364210289422701],"AUC_macro":[0.719345018125506],"balanced_accuracy":[0.6881783171898704],"recall_score_macro":[0.6881783171898704],"precision_score_weighted":[0.8893654459499262],"log_loss":[2.9165431630995475],"f1_score_macro":[0.7137896625728528],"precision_score_macro":[0.7530356809265832]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_7":{"accuracy":[0.9001517450682853],"precision_score_weighted":[0.8818702718242445],"f1_score_micro":[0.9001517450682853],"norm_macro_recall":[0.25286516364821887],"weighted_accuracy":[0.968108809323728],"AUC_micro":[0.9706957476841032],"matthews_correlation":[0.36880911120137455],"f1_score_weighted":[0.8823954076335154],"recall_score_macro":[0.6264325818241094],"average_precision_score_macro":[0.7567618681772804],"balanced_accuracy":[0.6264325818241094],"log_loss":[0.22850060928637927],"recall_score_micro":[0.9001517450682853],"average_precision_score_weighted":[0.9374324693168032],"f1_score_macro":[0.6630574616397639],"recall_score_weighted":[0.9001517450682853],"AUC_weighted":[0.9208599844029882],"average_precision_score_micro":[0.9690855705312702],"precision_score_micro":[0.9001517450682853],"AUC_macro":[0.9208599844029883],"precision_score_macro":[0.7689578875609304]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_15":{"AUC_macro":[0.9198041296885969],"balanced_accuracy":[0.5927642461660434],"log_loss":[0.21483807774148656],"weighted_accuracy":[0.9753312307699207],"f1_score_micro":[0.8992412746585736],"AUC_micro":[0.9720934602250617],"average_precision_score_macro":[0.7689561739388638],"average_precision_score_micro":[0.9734097967855523],"average_precision_score_weighted":[0.9400612115340252],"recall_score_micro":[0.8992412746585736],"AUC_weighted":[0.919804129688597],"matthews_correlation":[0.3271333527006733],"recall_score_weighted":[0.8992412746585736],"precision_score_macro":[0.7884091524271901],"f1_score_weighted":[0.8739813752034352],"precision_score_weighted":[0.8805111142554798],"norm_macro_recall":[0.1855284923320868],"recall_score_macro":[0.5927642461660434],"precision_score_micro":[0.8992412746585736],"accuracy":[0.8992412746585736],"f1_score_macro":[0.6255599794080923]},"4120a8f3-c9a7-462a-8908-224627bb4a0d_31":{"average_precision_score_macro":[0.8186104139180449],"AUC_macro":[0.9418659360892994],"AUC_weighted":[0.9418659360892994],"weighted_accuracy":[0.9518725603287422],"f1_score_weighted":[0.9097783194067844],"average_precision_score_weighted":[0.9535604080734286],"recall_score_macro":[0.7528651636482189],"precision_score_macro":[0.7836233799153131],"AUC_micro":[0.978978679702773],"f1_score_micro":[0.9122913505311078],"matthews_correlation":[0.5356060954722102],"norm_macro_recall":[0.5057303272964377],"accuracy":[0.9122913505311078],"balanced_accuracy":[0.7528651636482189],"recall_score_micro":[0.9122913505311078],"log_loss":[0.18420822105258325],"precision_score_micro":[0.9122913505311078],"recall_score_weighted":[0.9122913505311078],"f1_score_macro":[0.7669823064091336],"average_precision_score_micro":[0.9799438059930927],"precision_score_weighted":[0.9079165423122104]}}